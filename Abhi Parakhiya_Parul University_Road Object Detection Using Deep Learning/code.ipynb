{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b303d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 137 610 340\n",
      "0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 188.6ms\n",
      "Speed: 7.3ms preprocess, 188.6ms inference, 10.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 143 637 336\n",
      "0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 111.9ms\n",
      "Speed: 3.9ms preprocess, 111.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 120 632 358\n",
      "0.81\n",
      "8 150 481 322\n",
      "0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 112.1ms\n",
      "Speed: 3.6ms preprocess, 112.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 144 632 335\n",
      "0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 110.8ms\n",
      "Speed: 3.3ms preprocess, 110.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 149 581 327\n",
      "0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 120.4ms\n",
      "Speed: 5.7ms preprocess, 120.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 136 621 342\n",
      "0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BSTR.__del__ at 0x000001C31F633A30>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Abhi\\anaconda3\\lib\\site-packages\\comtypes\\__init__.py\", line 699, in __del__\n",
      "    def __del__(self, _free=windll.oleaut32.SysFreeString):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 147 452 316\n",
      "0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 152.5ms\n",
      "Speed: 6.9ms preprocess, 152.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 117 621 362\n",
      "0.7\n",
      "1 146 480 325\n",
      "0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 94.4ms\n",
      "Speed: 4.4ms preprocess, 94.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 140 512 336\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 110.2ms\n",
      "Speed: 3.8ms preprocess, 110.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 110 627 369\n",
      "0.73\n",
      "3 146 490 326\n",
      "0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 113.0ms\n",
      "Speed: 2.9ms preprocess, 113.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 148 631 330\n",
      "0.82\n",
      "23 147 460 317\n",
      "0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 103.8ms\n",
      "Speed: 2.0ms preprocess, 103.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 153 622 325\n",
      "0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 105.6ms\n",
      "Speed: 1.5ms preprocess, 105.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 175 542 304\n",
      "0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 126.7ms\n",
      "Speed: 5.6ms preprocess, 126.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 150 577 327\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 126.1ms\n",
      "Speed: 2.3ms preprocess, 126.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 153 623 326\n",
      "0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 116.1ms\n",
      "Speed: 3.3ms preprocess, 116.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 159 609 320\n",
      "0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 98.6ms\n",
      "Speed: 1.0ms preprocess, 98.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 160 618 319\n",
      "0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 113.7ms\n",
      "Speed: 3.6ms preprocess, 113.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 161 608 318\n",
      "0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 106.7ms\n",
      "Speed: 2.2ms preprocess, 106.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 164 593 315\n",
      "0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 106.0ms\n",
      "Speed: 1.0ms preprocess, 106.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 163 592 316\n",
      "0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 99.7ms\n",
      "Speed: 2.3ms preprocess, 99.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 154 624 325\n",
      "0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 107.5ms\n",
      "Speed: 3.0ms preprocess, 107.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 150 611 329\n",
      "0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 126.1ms\n",
      "Speed: 3.2ms preprocess, 126.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 154 591 325\n",
      "0.78\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "import pyttsx3\n",
    "\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "model = YOLO(\"../YOLO-Weights/yolov8n.pt\")\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\", \"traffic light\", \"fire hydrant\", \n",
    "              \"stop sign\", \"parking meter\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"backpack\",\n",
    "              \"umbrella\",\"handbag\", \"tie\", \"suitcase\", \"skateboard\",  \"bottle\", \"banana\", \"apple\", \n",
    "              \"orange\", \"broccoli\", \"toilet\", \"cell phone\",\"sink\", \"book\", \"teddy bear\", \"Helmet wearing\", \n",
    "              \"Pothole\", \"Narrow road\", \"Wide Road\"        ]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)    \n",
    "cap.set(4, 720)     \n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "\n",
    "          \n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "           \n",
    "\n",
    "            w, h = x2-x1, y2-y1\n",
    "            print(x1, y1, w, h)      \n",
    "            cvzone.cornerRect(img, (x1, y1, w, h), colorC=(0, 255, 0), colorR=(0,0,0), rt=3, t=5)  \n",
    "          \n",
    "            conf = math.ceil((box.conf[0]*100))/100   \n",
    "            print(conf)\n",
    "           \n",
    "            cls = int(box.cls[0])\n",
    "            cvzone.putTextRect(img, f\"{classNames[cls]} {conf}\", (max(0, x1 + 5), max(35, y1 - 15)), thickness=2, colorR=(0, 0, 0),\n",
    "                               scale=2)\n",
    "\n",
    "            engine.say(classNames[cls])\n",
    "            engine.runAndWait()\n",
    "\n",
    "    cv2.imshow(\"Image\", img)   \n",
    "    cv2.waitKey(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a835200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
